{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "homeless-rendering",
   "metadata": {},
   "source": [
    "# Forecasting Environments\n",
    "\n",
    "In this chapter, we're going to do a tour of forecasting *environments*: that is, the set of slices of time that you might need to put together when doing any forecast exercise. There won't be too much code in this chapter: we're just laying the theoretical groundwork here.\n",
    "\n",
    "Let's start with some definitions. Features, or regressors, are labelled by $k = 0, \\dots, K-1$ and time by $t = 0, \\dots, T-1$. Note that this means there are $T$ time periods and $K$ features. We'll label different slices of time (or equivalently models trained on different data) by an index $\\mu$ beginning from $\\mu=1$, and we'll give these slices of time different labels: IS for in-sample and OS for out-of-sample. $f_\\mu$ is the model trained on the $\\mu$th set of in-sample data. The target variable (the number we are trying to forecast) is $\\left\\{y_{t+h}\\right\\}_{t=0}^{t=T-1}$, where $h$ is the number of time steps ahead we wish to forecast. Let $\\left\\{x_{tk}\\right\\}_{t=0}^{t=T-1}$ represent feature (or regressor) $k$. This is a bit simplistic because of real-time data timeliness, but in general a forecast implies $h>0$ (otherwise we're doing a nowcast).\n",
    "\n",
    "## Two Period Forecast\n",
    "\n",
    "The most simple forecast you can imagine is if we have two periods (each of which may be made up of more than one value of $t$). The important thing is that the $t$ in the first, \"in-sample\" period do not overlap with the $t$ in the second, \"out-of-sample\" period. That's because we *only want to use information in the in-sample period to forecast the out-of-sample period*. There are some cases where you may want to \"forecast\" the in-sample period, but if you're interested in the real-world performance of your forecast, this is the setup you need.\n",
    "\n",
    "In this world of a single in-sample period and a single out-of-sample period, $\\mu=1$, and we could get drop that notation and just use IS and OS. But we'll leave it in to make the contrast with what's to come clearer.\n",
    "\n",
    "The exercise is to use a model, $f = f_{\\mu=1}$, that is trained to predict $\\{y_{t+h}, t:\\mu_{\\text{IS}}=1\\}$ using $\\{x_{tk}, t:\\mu_{\\text{IS}}=1\\}$ so that it can do an out-of-sample forecast of $\\{y_{t+h}, t:\\mu_\\text{OS}=1\\}$ using $\\{x_{tk}, t:\\mu_{\\text{OS}}=1\\}$. It's actually easier to see it with a picture:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "printable-humanity",
   "metadata": {
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Plot settings\n",
    "plt.style.use(\n",
    "    \"https://github.com/aeturrell/coding-for-economists/raw/main/plot_style.txt\"\n",
    ")\n",
    "# Set max rows displayed for readability\n",
    "pd.set_option(\"display.max_rows\", 15)\n",
    "\n",
    "from plotnine import ggplot, geom_point, aes, stat_smooth, facet_wrap\n",
    "from plotnine import (\n",
    "    options,\n",
    "    geom_tile,\n",
    "    scale_size,\n",
    "    scale_x_continuous,\n",
    "    scale_y_continuous,\n",
    ")\n",
    "from plotnine.scales import scale_fill_brewer\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "s = 1\n",
    "alpha = 4\n",
    "T = 10\n",
    "\n",
    "options.set_option(\"figure_size\", (12, 3))\n",
    "options.set_option(\"dpi\", 150)\n",
    "\n",
    "\n",
    "def in_sample_block_e(mu, s, alpha, T):\n",
    "    xf = pd.DataFrame({\"t\": np.arange(0, mu * s + alpha, s)})\n",
    "    xf[r\"$\\mu$\"] = [mu] * (mu * s + alpha - 0)\n",
    "    xf[\"sample\"] = \"in-sample\"\n",
    "    return xf\n",
    "\n",
    "\n",
    "def os_sample_block_e(mu, s, alpha, T):\n",
    "    xf = pd.DataFrame({\"t\": np.arange(mu * s + alpha, T, s)})\n",
    "    xf[r\"$\\mu$\"] = [mu] * (T - (mu * s + alpha))\n",
    "    xf[\"sample\"] = \"out-of-sample\"\n",
    "    return xf\n",
    "\n",
    "\n",
    "def in_sample_block_r(mu, s, alpha, T):\n",
    "    xf = pd.DataFrame({\"t\": np.arange((mu - 1) * s, mu * s + alpha, s)})\n",
    "    xf[r\"$\\mu$\"] = [mu] * (mu * s + alpha - (mu - 1) * s)\n",
    "    xf[\"sample\"] = \"in-sample\"\n",
    "    return xf\n",
    "\n",
    "\n",
    "def os_sample_block_r(mu, s, alpha, T):\n",
    "    xf = pd.DataFrame({\"t\": np.arange(mu * s + alpha, T, s)})\n",
    "    xf[r\"$\\mu$\"] = [mu] * (T - (mu * s + alpha))\n",
    "    xf[\"sample\"] = \"out-of-sample\"\n",
    "    return xf\n",
    "\n",
    "\n",
    "(\n",
    "    ggplot(aes(\"t\", \"sample\", r\"$\\mu$\"))\n",
    "    + geom_tile(\n",
    "        in_sample_block_e(1, s, alpha, T), aes(width=0.95, height=0.95, fill=\"sample\")\n",
    "    )\n",
    "    + geom_tile(\n",
    "        os_sample_block_e(1, s, alpha, T), aes(width=0.95, height=0.95, fill=\"sample\")\n",
    "    )\n",
    "    + scale_x_continuous(breaks=range(11))\n",
    "    + scale_fill_brewer(type=\"qual\", palette=\"Accent\")\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "tested-frontier",
   "metadata": {},
   "source": [
    "In this case, the in-sample period runs from $t=0$ to $t=4$, while the out-of-sample period runs from $t=5$ to $t=9$. $T=10$.\n",
    "\n",
    "Let's see how it works with some fake data, and we'll assume $h=3$ in this case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "optical-meditation",
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "\n",
    "horizon = 3\n",
    "num = 10 + horizon\n",
    "\n",
    "df = pd.DataFrame(\n",
    "    np.array(\n",
    "        [\n",
    "            range(num),\n",
    "            list(string.ascii_lowercase)[:num],\n",
    "            list(string.ascii_lowercase)[num : 2 * num],\n",
    "        ]\n",
    "    ).T,\n",
    "    columns=[\"Time\", \"y\", \"x\"],\n",
    ")\n",
    "df[r\"$y_{t+h}$\"] = df[\"y\"].shift(-horizon)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "explicit-queen",
   "metadata": {},
   "source": [
    "What we have here is a dataset with a time index and y and x values. $y_{t+h}$ has been added as a feature by shifting the $y$ variable back by $h=3$ steps. We're not going to be able to predict those NaN values, so the first thing to do is to drop those variables. Second, we'll want to add in which parts are in-sample and which are out-of-sample."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "celtic-relationship",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.dropna()\n",
    "df[\"sample\"] = df[\"Time\"].apply(lambda x: \"IS\" if int(x) < 5 else \"OS\")\n",
    "df = df.set_index(\"Time\")\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "canadian-chair",
   "metadata": {},
   "source": [
    "Note how the sample can either be IS or OS-but not both.\n",
    "\n",
    "Now, if we were doing a forecast, we'd select the IS part to do our initial model building by running something like\n",
    "\n",
    "```python\n",
    "model = ols.fit(X=df.loc[df[\"sample\"]==\"IS\",\"x\"],\n",
    "                y=df.loc[df[\"sample\"]==\"IS\",r\"$y_{t+h}$\"])\n",
    "```\n",
    "\n",
    "This would then be used to predict the out of sample values:\n",
    "\n",
    "```python\n",
    "y_t_plus_h_os = model.predict(X=df.loc[df[\"sample\"]==\"OS\",\"x\"])\n",
    "```\n",
    "\n",
    "To know how good the estimate was, we'd then compare it with the true value. Typically, a value like the root mean square error is used for this, given by\n",
    "\n",
    "$$\n",
    "{\\displaystyle \\operatorname {RMSE} ={\\sqrt {\\frac {\\sum _{t=0}^{T-1}({\\hat {y}}_{t+h}-y_{t+h})^{2}}{T}}}.}\n",
    "$$\n",
    "\n",
    "where $\\hat{y}_{t+h}$ is the predicted value, equivalent to the object `y_t_plus_h_os` above.\n",
    "\n",
    "### An Example Two Period Forecast\n",
    "\n",
    "Let's see an example of this with some numerical data. Our dataframe needs to have our features, $x$, and target, $y_{t+h}$, in."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "982d0432",
   "metadata": {},
   "outputs": [],
   "source": [
    "T = 10\n",
    "window_size = 5\n",
    "horizon = 3\n",
    "\n",
    "\n",
    "df = pd.DataFrame(\n",
    "    {\n",
    "        \"x\": range(0, T + horizon),\n",
    "        \"y\": [0] * horizon\n",
    "        + list(range(0, window_size))\n",
    "        + list(range(T - 1, window_size - 1, -1)),\n",
    "    }\n",
    ")\n",
    "df[\"x\"] = df[\"x\"].astype(float)\n",
    "# Bring y_{t+h} in line with feature x so that models always take data from the same row.\n",
    "# Note that for a variable to be at t+h today, with h the horizon, we need to bring it *back* by h steps\n",
    "df[r\"$y_{t+h}$\"] = df[\"y\"].shift(-horizon)\n",
    "# drop y so that we don't accidentally put it into model as a feature by mistake\n",
    "df = df.drop(\"y\", axis=1)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5100064",
   "metadata": {},
   "source": [
    "As ever, it's good to look at your data so let's do a quick chart. Note that time and $x$ have the same values here, so this is also the time series of $y_{t+h}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7247beed",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.plot.scatter(x=\"x\", y=r\"$y_{t+h}$\");"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac43ddbf",
   "metadata": {},
   "source": [
    "Okay, what could possibly go wrong! Let's now do our forecasting exercise. First, we train or fit the model. Note that *pandas* indexing is *inclusive*, so we run to `window_size-1` rather than `window_size` to pick up our 5 in-sample points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad736000",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "df = df.dropna()\n",
    "model = LinearRegression(fit_intercept=False).fit(\n",
    "    X=df.loc[: window_size - 1, [\"x\"]], y=df.loc[: window_size - 1, [r\"$y_{t+h}$\"]]\n",
    ")\n",
    "# Make in-sample prediction. Note that the predictions of the model come out in\n",
    "# an array of form [[a], [b], ...] so we flatten this to [a, b, ...]. Also, we pad\n",
    "# the results we didn't predict with [None]\n",
    "df[r\"$\\hat{y}_{t+h}^{\\operatorname{IS}}$\"] = list(\n",
    "    model.predict(df.loc[: window_size - 1, [\"x\"]]).flatten()\n",
    ") + [None] * (window_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e51c7466",
   "metadata": {},
   "source": [
    "Make out of sample prediction:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2434c1f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[r\"$\\hat{y}_{t+h}^{\\operatorname{OS}}$\"] = [None] * (window_size) + list(\n",
    "    model.predict(df.loc[window_size:, [\"x\"]]).flatten()\n",
    ")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "141aa6b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "df.plot.scatter(x=\"x\", y=r\"$y_{t+h}$\", ax=ax, label=r\"$y_{t+h}$\", s=80)\n",
    "df.plot.scatter(\n",
    "    x=\"x\",\n",
    "    y=r\"$\\hat{y}_{t+h}^{\\operatorname{OS}}$\",\n",
    "    color=\"red\",\n",
    "    ax=ax,\n",
    "    label=r\"$\\hat{y}_{t+h}^{\\operatorname{OS}}$\",\n",
    "    s=100,\n",
    ")\n",
    "ax.set_ylabel(r\"$y_{t+h}$ and $\\hat{y}_{t+h}^{\\operatorname{OS}}$\")\n",
    "ax.legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6e73467",
   "metadata": {},
   "source": [
    "Oh dear, it doesn't look like our out-of-sample prediction did very well! Let's see what the RMSE error is for both the in-sample and out-of-sample prediction."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edf0c1c6",
   "metadata": {},
   "source": [
    "## Expanding Window\n",
    "\n",
    "In an expanding window forecast exercise, multiple forecasts are made. In each, the in-sample period grows over time. Necessarily (given finite data), the out-of-sample period shrinks over time. The overall out-of-sample forecast is given by the unique union of the out-of-sample forecasts that are trained on the most information. To make this clear, let's first define it mathematically and then with a diagram.\n",
    "\n",
    "We index the different forecasts (synoymous with different models $f_\\mu$) by $\\mu$. The starting size of the window will be $s + \\alpha$ where $s$ is the step size and $\\alpha$ is a parameter that adjusts window size. For arbitrary $z_t$, the $\\mu$th in-sample slice of time series data is: \n",
    "$$\n",
    "I_{\\mu}(\\vec{z}) = \\left\\{z_t  \\right\\}_{t=0}^{t=\\mu\\cdot s + \\alpha -1}\n",
    "$$\n",
    "Applied to the features, this is the slice that will be used to train (aka fit) model $f_\\mu$.\n",
    "\n",
    "Likewise, the out-of-sample set is:\n",
    "$$\n",
    "O_{\\mu}(\\vec{z}) = \\left\\{z_t \\right\\}^{t=T-1}_{t=\\mu\\cdot s + \\alpha}\n",
    "$$\n",
    "\n",
    "We can visualise this like so:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e43316e",
   "metadata": {
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "# TODO: hide-input tag\n",
    "from plotnine import ggtitle\n",
    "\n",
    "s = 1\n",
    "alpha = 2\n",
    "T = 10\n",
    "max_mu = int((T - 1 + 1 - alpha) / s)\n",
    "\n",
    "(\n",
    "    ggplot(aes(\"t\", r\"$\\mu$\", \"sample\"))\n",
    "    + [\n",
    "        geom_tile(\n",
    "            os_sample_block_e(mu, s, alpha, T),\n",
    "            aes(width=0.95, height=0.95, fill=\"sample\"),\n",
    "        )\n",
    "        for mu in range(1, max_mu)\n",
    "    ]\n",
    "    + [\n",
    "        geom_tile(\n",
    "            in_sample_block_e(mu, s, alpha, T),\n",
    "            aes(width=0.95, height=0.95, fill=\"sample\"),\n",
    "        )\n",
    "        for mu in range(1, max_mu)\n",
    "    ]\n",
    "    + scale_x_continuous(breaks=range(T + 1))\n",
    "    + scale_y_continuous(breaks=range(1, max_mu))\n",
    "    + scale_fill_brewer(type=\"qual\", palette=\"Accent\")\n",
    "    + ggtitle(\"Expanding Window\")\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d36b185b",
   "metadata": {},
   "source": [
    "Note that in-sample and out-of-sample never overlap in time for the same value of $\\mu$. This is important because it ensures "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9916745e",
   "metadata": {},
   "outputs": [],
   "source": [
    "script_O = pd.concat(\n",
    "    [os_sample_block_e(mu, s, alpha, T) for mu in range(1, max_mu)], axis=0\n",
    ")\n",
    "script_O = script_O.reset_index(drop=True)\n",
    "script_O[\"Union\"] = False\n",
    "script_O.loc[script_O[~script_O[\"t\"].duplicated(keep=\"last\")].index, \"Union\"] = True\n",
    "script_O"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44a355a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "(\n",
    "    ggplot(aes(\"t\", r\"$\\mu$\", \"Union\"))\n",
    "    + geom_tile(script_O, aes(width=0.95, height=0.95, fill=\"Union\"))\n",
    "    + scale_x_continuous(breaks=range(T), limits=(-1, T))\n",
    "    + scale_y_continuous(breaks=range(1, max_mu))\n",
    "    + scale_fill_brewer(type=\"qual\", palette=\"Pastel1\")\n",
    "    + ggtitle(\"Union of Best Expanding Window Out-of-Sample Predictions\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88bb1e14",
   "metadata": {},
   "outputs": [],
   "source": [
    "script_I = pd.concat(\n",
    "    [in_sample_block_e(mu, s, alpha, T) for mu in range(1, max_mu)], axis=0\n",
    ")\n",
    "script_I = script_I.reset_index()\n",
    "# def script_is_e(s, alpha, df):\n",
    "script_I[\"Union\"] = False\n",
    "script_I.loc[script_I[~script_I[\"t\"].duplicated(keep=\"first\")].index, \"Union\"] = True\n",
    "script_I"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20dd93b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "(\n",
    "    ggplot(aes(\"t\", r\"$\\mu$\", \"Union\"))\n",
    "    + geom_tile(script_I, aes(width=0.95, height=0.95, fill=\"Union\"))\n",
    "    + scale_x_continuous(breaks=range(T), limits=(-1, T))\n",
    "    + scale_y_continuous(breaks=range(1, max_mu))\n",
    "    + scale_fill_brewer(type=\"qual\", palette=\"Pastel1\")\n",
    "    + ggtitle(\"Union of Best Expanding Window In-Sample Predictions\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cedaf624",
   "metadata": {
    "tags": [
     "remove-cell"
    ]
   },
   "outputs": [],
   "source": [
    "# TODO hide all\n",
    "# For completeness, this is what the IS and OS time series look like next to each other:\n",
    "\n",
    "script_I[\"sample\"] = \"In-Sample\"\n",
    "script_O[\"sample\"] = \"Out-of-Sample\"\n",
    "script_rolling = pd.concat([script_I, script_O], axis=0)\n",
    "script_rolling = script_rolling[script_rolling[\"Union\"] == True]\n",
    "\n",
    "(\n",
    "    ggplot(aes(\"t\", r\"$\\mu$\", \"sample\"))\n",
    "    + geom_tile(script_rolling, aes(width=0.95, height=0.95, fill=\"sample\"))\n",
    "    + scale_x_continuous(breaks=range(T), limits=(-1, T))\n",
    "    + scale_y_continuous(breaks=range(1, max_mu))\n",
    "    + scale_fill_brewer(type=\"qual\", palette=\"Accent\")\n",
    "    + ggtitle(\"Best Expanding Window Predictions: In-Sample and Out-of-Sample\")\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a802fce8",
   "metadata": {},
   "source": [
    "## Rolling Window\n",
    "\n",
    "Below is example of all the rolling window forecasts in a single forecasting exercise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4275efa6",
   "metadata": {
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "# TODO: hide-input tag\n",
    "from plotnine import ggtitle\n",
    "\n",
    "s = 1\n",
    "alpha = 2\n",
    "window_size = s + alpha\n",
    "T = 10\n",
    "max_mu = int((T - 1 + 1 - alpha) / s)\n",
    "\n",
    "(\n",
    "    ggplot(aes(\"t\", r\"$\\mu$\", \"sample\"))\n",
    "    + [\n",
    "        geom_tile(\n",
    "            in_sample_block_r(mu, s, alpha, T),\n",
    "            aes(width=0.95, height=0.95, fill=\"sample\"),\n",
    "        )\n",
    "        for mu in range(1, max_mu)\n",
    "    ]\n",
    "    + [\n",
    "        geom_tile(\n",
    "            os_sample_block_r(mu, s, alpha, T),\n",
    "            aes(width=0.95, height=0.95, fill=\"sample\"),\n",
    "        )\n",
    "        for mu in range(1, max_mu)\n",
    "    ]\n",
    "    + scale_x_continuous(breaks=range(T + 1))\n",
    "    + scale_y_continuous(breaks=range(1, max_mu))\n",
    "    + scale_fill_brewer(type=\"qual\", palette=\"Accent\")\n",
    "    + ggtitle(\"Rolling Window\")\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49e0057d",
   "metadata": {},
   "source": [
    "Unions\n",
    "\n",
    "Below shows how to find *overall* performance of the forecast. These are best out-of-sample predictions possible. These are going to be the union of one step ahead forecasts (ie forecasts that are just outside of the in-sample period)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4f5226d",
   "metadata": {},
   "outputs": [],
   "source": [
    "script_I = pd.concat(\n",
    "    [in_sample_block_r(mu, s, alpha, T) for mu in range(1, max_mu)], axis=0\n",
    ")\n",
    "script_I = script_I.reset_index()\n",
    "# def script_is_e(s, alpha, df):\n",
    "script_I[\"Union\"] = False\n",
    "script_I.loc[script_I[~script_I[\"t\"].duplicated(keep=\"first\")].index, \"Union\"] = True\n",
    "script_I"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ddfb2bc",
   "metadata": {},
   "source": [
    "Below gives best in-sample prediction because it is union of last period within-the-window predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2255d46a",
   "metadata": {},
   "outputs": [],
   "source": [
    "(\n",
    "    ggplot(aes(\"t\", r\"$\\mu$\", \"Union\"))\n",
    "    + geom_tile(script_I, aes(width=0.95, height=0.95, fill=\"Union\"))\n",
    "    + scale_x_continuous(breaks=range(T), limits=(-1, T))\n",
    "    + scale_y_continuous(breaks=range(1, max_mu))\n",
    "    + scale_fill_brewer(type=\"qual\", palette=\"Pastel1\")\n",
    "    + ggtitle(\"Union of Best Rolling Window In-Sample Predictions\")\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb7a7fd8",
   "metadata": {},
   "source": [
    "below gives best out-of-sample predictions because it is the union of *just* out-of-sample forecasts (by one step size)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e125a6fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "script_O = pd.concat(\n",
    "    [os_sample_block_r(mu, s, alpha, T) for mu in range(1, max_mu)], axis=0\n",
    ")\n",
    "script_O = script_O.reset_index()\n",
    "script_O[\"Union\"] = False\n",
    "script_O.loc[script_O[~script_O[\"t\"].duplicated(keep=\"last\")].index, \"Union\"] = True\n",
    "script_O"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b3cb0c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "(\n",
    "    ggplot(aes(\"t\", r\"$\\mu$\", \"Union\"))\n",
    "    + geom_tile(script_O, aes(width=0.95, height=0.95, fill=\"Union\"))\n",
    "    + scale_x_continuous(breaks=range(T), limits=(-1, T))\n",
    "    + scale_y_continuous(breaks=range(1, max_mu))\n",
    "    + scale_fill_brewer(type=\"qual\", palette=\"Pastel1\")\n",
    "    + ggtitle(\"Union of Best Rolling Window Out-of-Sample Predictions\")\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f20e0fae",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbbe2389",
   "metadata": {
    "tags": [
     "remove-cell"
    ]
   },
   "outputs": [],
   "source": [
    "# TODO hide all\n",
    "# For completeness, this is what the IS and OS time series look like next to each other:\n",
    "\n",
    "script_I[\"sample\"] = \"In-Sample\"\n",
    "script_O[\"sample\"] = \"Out-of-Sample\"\n",
    "script_rolling = pd.concat([script_I, script_O], axis=0)\n",
    "script_rolling = script_rolling[script_rolling[\"Union\"] == True]\n",
    "\n",
    "(\n",
    "    ggplot(aes(\"t\", r\"$\\mu$\", \"sample\"))\n",
    "    + geom_tile(script_rolling, aes(width=0.95, height=0.95, fill=\"sample\"))\n",
    "    + scale_x_continuous(breaks=range(T), limits=(-1, T))\n",
    "    + scale_y_continuous(breaks=range(1, max_mu))\n",
    "    + scale_fill_brewer(type=\"qual\", palette=\"Accent\")\n",
    "    + ggtitle(\"Best Rolling Window Predictions: In-Sample and Out-of-Sample\")\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "671f4d32165728098ed6607f79d86bfe6b725b450a30021a55936f1af379a247"
  },
  "jupytext": {
   "cell_metadata_filter": "-all",
   "formats": "md:myst"
  },
  "kernelspec": {
   "display_name": "Python 3.8.6 64-bit ('codeforecon': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
