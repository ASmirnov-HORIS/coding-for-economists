{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Statistics, Randomness, and Probability\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "In this chapter, you'll learn about doing statistics with code.\n",
    "\n",
    "This chapter uses the TODO, along with some others that we've already seen. If you're running this code, you may need to install these packages using, for example, `pip install packagename` on your computer's command line. (If you're not sure what a command line or terminal is, take a quick look at the basics of coding chapter.)\n",
    "\n",
    "### Notation\n",
    "\n",
    "Greek letters, like $\\beta$, are the truth. Modified Greek letters are an estimate of the truth, for example $\\hat{\\beta}$. Letters from the Latin alphabet denote the values of data, for instance $x$ for a variable or vector. Modified Latin alphabet letters denote computations performed on data, for instance $\\bar{x} = \\frac{1}{n} \\displaystyle\\sum_{i} x_i$ where $n$ is number of samples.\n",
    "\n",
    "### Imports\n",
    "\n",
    "First we need to import the packages we'll be using"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy import stats\n",
    "import pingouin as pg\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basics\n",
    "\n",
    "Let's start with computing the simplest statistics you can think of using some synthetic data. Many of the functions have lots of extra options that we won't explore here (like weights or normalisation); remember that you can see these using the `help()` method. \n",
    "\n",
    "We'll generate a vector with 100 entries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.array(range(100))\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "remove-cell"
    ]
   },
   "outputs": [],
   "source": [
    "from myst_nb import glue\n",
    "import sympy\n",
    "\n",
    "dict_fns = {'mean': np.mean(data),\n",
    "            'std': np.std(data),\n",
    "            'mode': stats.mode([0, 1, 2, 3, 3, 3, 5])[0][0],\n",
    "            'median': np.median(data)}\n",
    "\n",
    "for name, eval_fn in dict_fns.items():\n",
    "    glue(name, f'{eval_fn:.1f}')\n",
    "\n",
    "\n",
    "# Set max rows displayed for readability\n",
    "pd.set_option('display.max_rows', 6)\n",
    "# Plot settings\n",
    "plot_style = {'xtick.labelsize': 20,\n",
    "                  'ytick.labelsize': 20,\n",
    "                  'font.size': 22,\n",
    "                  'figure.autolayout': True,\n",
    "                  'figure.figsize': (10, 5.5),\n",
    "                  'axes.titlesize': 22,\n",
    "                  'axes.labelsize': 20,\n",
    "                  'lines.linewidth': 4,\n",
    "                  'lines.markersize': 6,\n",
    "                  'legend.fontsize': 16,\n",
    "                  'mathtext.fontset': 'stix',\n",
    "                  'font.family': 'STIXGeneral',\n",
    "                  'legend.frameon': False}\n",
    "plt.style.use(plot_style)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Okay, let's see how some basic statistics are computed. The mean is `np.mean(data)=`{glue:}`mean`, the standard deviation is `np.std(data)=`{glue:}`std`, and the median is given by `np.median(data)=`{glue:}`median`. The mode is given by `stats.mode([0, 1, 2, 3, 3, 3, 5])[0]=`{glue:}`mode` (access the counts using `stats.mode(...)[1]`).\n",
    "\n",
    "Less famous quantiles than the median are given by, for example for $q=0.25$,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.quantile(data, 0.25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As with **pandas**, **numpy** and **scipy** work on scalars, vectors, matrices, and tensors: you just need to specify the axis that you'd like to apply a function to:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.fromfunction(lambda i, j: i + j, (3, 6), dtype=int)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(data, axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remember that, for discrete data points, the $k$th (unnormalised) moment is\n",
    "\n",
    "$$\n",
    "m_k = \\frac{1}{n}\\displaystyle\\sum_{i=1}^{n} \\left(x_i - \\bar{x}\\right)^k\n",
    "$$\n",
    "\n",
    "To compute this use scipy's `stats.moment(a, moment=1)`. For instance for the kurtosis ($k=4$), it's"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats.moment(data, moment=4, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Covariances are found using `np.cov`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.cov(np.array([[0, 1, 2], [2, 1, 0]]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that, as expected, the $C_{01}$ term is -1 as the vectors are anti-correlated."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Randomness\n",
    "\n",
    "In this section, we'll see how to generate random numbers. Numpyâ€™s random number routines produce pseudo-random numbers, which is the best that any computer can do. If you care about how, the default PRNG (psuedo-random number generator) is a 64-bit Permuted Congruential Generator, though you can access other generators too.\n",
    "\n",
    "The way to use the numpy PRNG is to call it in like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy.random import default_rng\n",
    "rng = default_rng()\n",
    "x_vals = rng.random(size=2)\n",
    "x_vals"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the above, `rng` is an object that you can call many random number generating functions on. Here we just asked for 2 values drawn from between 0 and 1.\n",
    "\n",
    "Another really useful random generator provides integers and is called `integers`. Let's see this but in the case where we're asking for a more elaborately shaped output array, a 3x3x2 dimensional tensor:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_int = 1\n",
    "max_int = 20\n",
    "rng.integers(min_int, max_int, size=(3, 3, 2))"
   ]
  },
  {
   "source": [
    "One random function that is incredibly useful is `choice`, which returns a random selection from another type of object. Here, we show this by passing a list of letters and asking for two of them to be picked randomly:"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rng.choice(['a', 'b', 'c', 'd', 'e', 'f'], size=2)"
   ]
  },
  {
   "source": [
    "This choice can also be made with a given probability. Let's make a very large number of draws with an exponentially falling probability and see what we get!"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_draws = 1000\n",
    "# Create 6 values spread across several orders of magnitude\n",
    "prob = np.logspace(0, -3, num=6)\n",
    "# Normalise this to 1\n",
    "prob = prob/sum(prob)\n",
    "# Choose the letters\n",
    "letter_choices = rng.choice(['a', 'b', 'c', 'd', 'e', 'f'], size=num_draws, p=prob)"
   ]
  },
  {
   "source": [
    "To make it easy to see what happened, we'll use the in-built collections library's `Counter` function to go from a long list of all of the letters to a dictionary of letters and counts of how frequently they occurred:"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "counts = Counter(letter_choices)\n",
    "plt.bar(counts.keys(), counts.values());"
   ]
  },
  {
   "source": [
    "As expected, 'a' was chosen many more times than 'b', and so on. In fact, if we divided the counts by `num_draws`, we would find that the probability of each letter was converging toward the probabilities we provided in `prob`.\n",
    "\n",
    "Another useful random function to know about is `shuffle`, and you can probably guess what it does! But note that it does the shuffling to the list you put in, rather than returning a new, modified list. Here's an example:"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plain_list = ['This', 'list', 'is', 'well', 'ordered.']\n",
    "rng.shuffle(plain_list)\n",
    "plain_list"
   ]
  },
  {
   "source": [
    "If you are using **pandas** for your analysis, then it comes with random sampling methods built in under the guise of `df.sample()` for a dataframe `df`. This has keywords for number of samples (`n`) **or** fraction of all rows to sample (`frac`) and whether to use `weights=`."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reproducibility\n",
    "\n",
    "If you need to create random numbers reproducibly, then you can do it by setting a seed value like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy.random import Generator, PCG64\n",
    "seed_for_prng = 54321\n",
    "prng = Generator(PCG64(seed_for_prng))\n",
    "prng.integers(0, 10, size=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prng = Generator(PCG64(seed_for_prng))\n",
    "prng.integers(0, 10, size=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The seed tells the generator where to start (PCG64 is the default generator), so by passing the same seed in we can make the random numbers begin in the same place.\n",
    "\n",
    "The `prng` above can also be passed to the **pandas** sample function as a keyword argument.\n",
    "\n",
    "### Random numbers drawn from distributions\n",
    "\n",
    "Using **numpy**, we can often draw samples from distributions using the `prng.distribution` syntax. One of the most common distributions you might like to draw from is the uniform, for example\n",
    "\n",
    "$$\n",
    "x \\thicksim \\mathcal{U}(0, 10)\n",
    "$$\n",
    "\n",
    "with, here, a minimum of 0 and a maximum of 10. Here's the code:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prng.uniform(low=0, high=10, size=3)"
   ]
  },
  {
   "source": [
    "Let's see how to draw from one other important distribution function: the Gaussian, or normal, distribution $x \\thicksim \\mathcal{N}\\left(\\mu, \\sigma\\right)$ and check that it looks right. We'll actually do two different ones: a standard normal, with $\\mu=0$ and $\\sigma=1$, and a shifted, relaxed one with different parameters."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gauss(x):\n",
    "    \"\"\"Analytical Gaussian.\"\"\"\n",
    "    return (1/np.sqrt(2*np.pi))*np.exp(-0.5*x**2)\n",
    "\n",
    "\n",
    "# Make the random draws\n",
    "num_draws = 10000\n",
    "vals = prng.standard_normal(num_draws)\n",
    "\n",
    "# Get analytical solution\n",
    "x_axis_vals = np.linspace(-3, 3, 300)\n",
    "analytic_y = gauss(x_axis_vals)\n",
    "\n",
    "# Random draws of shifted/flatter dist\n",
    "mu = 0.5\n",
    "sigma = 2\n",
    "vals_shift = prng.normal(loc=mu, scale=sigma, size=num_draws)\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(x_axis_vals, analytic_y, label='Std norm: analytical', lw=3)\n",
    "ax.hist(vals, bins=50, label='Std norm: generated', density=True, alpha=0.8)\n",
    "ax.hist(vals_shift, bins=50, label=f'Norm: $\\mu$={mu}, $\\sigma$={sigma}', density=True, alpha=0.8)\n",
    "ax.legend(frameon=False)\n",
    "plt.show()"
   ]
  },
  {
   "source": [
    "What if there isn't a pre-built distribution available? Well, first, that would be surprising, because there's a huge number of them! (More on that in a moment.) But a quick way to get around this is to plug random numbers into the inverse cumulative distribution function (assuming it exists) of your distribution function, ie you plug random numbers $r$ into $\\text{cdf}^{-1}(r)$ in order to generate $x \\thicksim \\text{pdf}$."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## Probability\n",
    "\n",
    "We've already seen some bits of probability and how to do them already; options for probabilistic sampling popped up in `df.sample` and `choices`, and, of course, probability density functions like the Gaussian have an intimate relationship with probability. Let's take a step back now and discuss what we mean by probability and random variables.\n",
    "\n",
    "A random variable is a function that maps a sample space $S$ into the real numbers $\\mathbb{R}$, i.e. $X:S\\rightarrow\\mathbb{R}$. Discrete random variables have a finite (or countably infinite) number of values (think integers); continuous random variables have infinitely many values (think a Gaussian).\n",
    "\n",
    "### Probability mass functions\n",
    "\n",
    "Even armed with this, we can do some very simple simulations of probability. We start with the canonical example, rolling a 6-sided die...\n",
    "\n",
    "..but we want to make it a *bit* more exciting than that! Let's see two die, one that's fair (equal probability of getting any value in 1 to 6) and one that's loaded (in this case, we'll make a 6 twice as likely as other values).\n",
    "\n",
    "A brief recap on probability: in this case our sample space is $S = {1, 2, 3, 4, 5, 6}$. To work out the probability of a particular value, it's going to be\n",
    "\n",
    "$$\n",
    "\\frac{\\text{Counts}_s}{\\text{Total counts}}\n",
    "$$\n",
    "\n",
    "with $s \\in {1, 2, 3, 4, 5, 6}$.\n",
    "\n",
    "To simualte this, we'll use the `choice` function fed with the six values, 1 to 6, on standard dice. Then we'll count the occurrences of each, creating a dictionary of keys and values with `Counter`, and then plot those."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import collections\n",
    "\n",
    "throws = 1000\n",
    "die_vals = np.arange(1, 7)\n",
    "probabilities = [1/7, 1/7, 1/7, 1/7, 1/7, 2/7]\n",
    "fair_throws = prng.choice(die_vals, size=throws)\n",
    "load_throws = prng.choice(die_vals, size=throws, p=probabilities)\n",
    "\n",
    "\n",
    "def throw_list_to_array(throw_list):\n",
    "    # Count frequencies of what's in throw list but order the dictionary keys\n",
    "    counts_dict = collections.OrderedDict(sorted(Counter(throw_list).items()))\n",
    "    # Turn the key value pairs into a numpy array\n",
    "    array = np.array([list(counts_dict.keys()), list(counts_dict.values())], dtype=float)\n",
    "    # Divide counts per value by num throws\n",
    "    array[1] = array[1]/len(throw_list)\n",
    "    return array\n",
    "\n",
    "\n",
    "counts_fair = throw_list_to_array(fair_throws)\n",
    "counts_load = throw_list_to_array(load_throws)\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.scatter(counts_fair[0],\n",
    "           counts_fair[1],\n",
    "           color='b',\n",
    "           label='Fair')\n",
    "ax.scatter(counts_load[0],\n",
    "           counts_load[1],\n",
    "           color='r',\n",
    "           label='Loaded')\n",
    "ax.set_xlabel('Die value')\n",
    "ax.set_ylabel('Probability')\n",
    "ax.axhline(1/6, color='k', alpha=0.3, linestyle='-.', lw=0.5)\n",
    "ax.legend(frameon=True, loc='upper left')\n",
    "ax.set_ylim(0., 0.4);"
   ]
  },
  {
   "source": [
    "To work out the probability based on the simulation, we've divided the number of throws per value by the total number of throws. You can see that with so many throws, there's quite a wedge between the chance of obtaining a six in both cases. Meanwhile, the fair die is converging to the dotted line, which is $1/6$. Note that because of the individual probabilities summing to unity, a higher probability of a six on the loaded die means that values 1 to 5 must have a lower probability than with the fair die; and you can see that emerging in the chart too.\n",
    "\n",
    "In doing this for every possible outcome, we're effectively estimating a probability mass function (if we rescale by the number of throws); an object that tells us the probabilty mass given to specific outcomes. The more precise defintion of a probability mass function (or pmf) is\n",
    "\n",
    "$$\n",
    "p(x_i) = P(X=x_i) = P(\\underbrace{\\{s\\in S\\ |\\ X(s) = x_i\\}}_{\\text{set of outcomes resulting in}\\ X=x_i}).\n",
    "$$\n",
    "\n",
    "It has a few key properties. The probability of all outcomes sum to 1, ie $\\displaystyle{\\sum_{x_i} p(x_i)}=1$, the probabilities satisfy $p(x_i) \\geq 0  \\quad\\forall x_i$, and $P(X \\in A) = \\displaystyle\\sum_{x_i \\in A} p(x_i)$.\n",
    "\n",
    "Another useful object is the cumulative distribution function, which is defined generally as $\\text{cdf}(x) = P(X \\leq x)\\quad \\forall x \\in \\mathbb{R}$. For probability mass functions, this becomes\n",
    "\n",
    "$$\n",
    "\\text{cdf}(x) = P(X\\leq x) = \\sum_{x_i\\leq x} p(x_i)\n",
    "$$\n",
    "\n",
    "Let's estimate the probability mass functions for our dice using the `cumsum` function: "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.plot(counts_fair[0],\n",
    "           np.cumsum(counts_fair[1]),\n",
    "           color='b',\n",
    "           label='Fair')\n",
    "ax.plot(counts_load[0],\n",
    "        np.cumsum(counts_load[1]),\n",
    "        color='r',\n",
    "           label='Loaded')\n",
    "ax.set_xlabel('Die value')\n",
    "ax.set_ylabel('Cumulative distribution function')\n",
    "ax.axhline(1, color='k', alpha=0.3, linestyle='-.', lw=0.5)\n",
    "ax.legend(frameon=True, loc='lower right')\n",
    "ax.set_ylim(0., 1.2);"
   ]
  },
  {
   "source": [
    "We can see that the cumulative distribution function also tells a story about what's going on; namely, there is a lower gradient up to $i=6$, followed by a higher gradient. The two distributions are visually distinct.\n",
    "\n",
    "Bernoulli and other famous discrete distributions."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "### Probability density functions\n",
    "\n",
    "PDFs are to continuous variables what PMFs are to discrete variables, though there are some important differences that trip up even the most careful.\n",
    "This is different to a probability density function!!!"
   ],
   "cell_type": "markdown",
   "metadata": {}
  }
 ],
 "metadata": {
  "celltoolbar": "Tags",
  "kernelspec": {
   "display_name": "codeforecon",
   "language": "python",
   "name": "codeforecon"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6-final"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}